{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Spline Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import torch\n",
    "import numpy as np\n",
    "import normflows as nf\n",
    "from torchviz import make_dot\n",
    "from sklearn.datasets import make_moons\n",
    "from scipy.special import erf, gamma\n",
    "import matplotlib as mat\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import benchmark\n",
    "import xfacpy\n",
    "from tqdm import tqdm\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.switch_backend('TkAgg')\n",
    "\n",
    "plt.style.use(['science'])\n",
    "fsize = 38\n",
    "mat.rcParams.update({'font.size': fsize})\n",
    "mat.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "#Colormap = [\"blue\", \"orange\", \"green\", \"red\", \"black\", \"brown\",\n",
    "#            \"pink\", \"gray\", \"olive\", \"cyan\",  \"black\"]\n",
    "pt_L = ['p', '^', 'v', 'o', 's', 'p', '<', 'h', '>', 'H', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate corresponding tensor based on the indices\n",
    "#xell is the grid of one dimension. Here we use the same uniform grid for all dimensions\n",
    "#nfm is the flow model.\n",
    "def Ptensor(I, J, zell, ndims, nfm, well=None):\n",
    "    # Generate input tensor\n",
    "    z = torch.zeros(len(I),len(J),ndims)\n",
    "    w = torch.ones(len(I),len(J))\n",
    "    for i, Idex in enumerate(I):\n",
    "        for j, Jdex in enumerate(J):\n",
    "            z[i,j,:] = torch.tensor(np.array([zell[k] for k in Idex+Jdex])) \n",
    "            if well is not None:\n",
    "                w[i,j] = reduce(lambda x, y: x * y, [well[k] for k in Idex+Jdex])\n",
    "    #result = torch.tensor(x2)\n",
    "    #print(\"test:\",result)\n",
    "    znewshape = (torch.prod(torch.tensor(z.shape[0:-1])).item(), z.shape[-1])\n",
    "    \n",
    "    # Reshape the input z two 2D tensor, (batchsize, ndims), required by the flow.prob.\n",
    "    x, logJ = nfm.forward_and_log_det(z.view(znewshape))\n",
    "    result = torch.exp(nfm.p.log_prob(x) + logJ)\n",
    "    # Reshape back to the Matrix form for loss calculation\n",
    "    return w*result.view(z.shape[0:-1])\n",
    "\n",
    "def Ttensor(I, P, J, zell, ndims, nfm, well=None,zfine=None, wfine=None):\n",
    "    z = torch.zeros(len(I),len(P), len(J), ndims)\n",
    "    w = torch.ones(len(I),len(P), len(J))\n",
    "    for i, Idex in enumerate(I):\n",
    "        for p, Pdex in enumerate(P):\n",
    "            for j, Jdex in enumerate(J):\n",
    "                if zfine is not None:\n",
    "                    grid = np.array([zell[k] for k in Idex]+[zfine[Pdex]]+[zell[k] for k in Jdex])\n",
    "                else:\n",
    "                    grid = np.array([zell[k] for k in Idex+[Pdex]+Jdex])\n",
    "                z[i,p,j,:] = torch.tensor(grid)\n",
    "                if well is not None:\n",
    "                    if wfine is not None:\n",
    "                        weight = [well[k] for k in Idex]+[wfine[Pdex]]+[well[k] for k in Jdex]\n",
    "                    else:\n",
    "                        weight = [well[k] for k in Idex+[Pdex]+Jdex]\n",
    "                    w[i,p,j] = reduce(lambda x, y: x * y,weight)\n",
    "    znewshape = (torch.prod(torch.tensor(z.shape[0:-1])).item(), z.shape[-1])\n",
    "    \n",
    "    # Reshape the input z two 2D tensor, (batchsize, ndims), required by the flow.prob.\n",
    "    x, logJ = nfm.forward_and_log_det(z.view(znewshape))\n",
    "    result = torch.exp(nfm.p.log_prob(x) + logJ)\n",
    "    # Reshape back to the Matrix form for loss calculation\n",
    "    return w*result.view(z.shape[0:-1])\n",
    "\n",
    "def Pitensor(I, P1, P2, J, zell, ndims, nfm, well=None, zfine=None, wfine=None):\n",
    "    z = torch.zeros(len(I),len(P1), len(P2),len(J), ndims)\n",
    "    w = torch.ones(len(I),len(P1), len(P2),len(J))\n",
    "    for i, Idex in enumerate(I):\n",
    "        for p1, P1dex in enumerate(P1):\n",
    "            for p2,P2dex in enumerate(P2):\n",
    "                for j, Jdex in enumerate(J):\n",
    "                    if zfine is not None:\n",
    "                        grid = np.array([zell[k] for k in Idex]+[zfine[P1dex]]+[zfine[P2dex]]+[zell[k] for k in Jdex])\n",
    "                    else:\n",
    "                        grid = np.array([zell[k] for k in Idex+[P1dex]+[P2dex]+Jdex])\n",
    "                    z[i,p1,p2,j,:] = torch.tensor(grid)  \n",
    "                    if well is not None:\n",
    "                        if wfine is not None:\n",
    "                            weight = [well[k] for k in Idex]+[wfine[P1dex]]+[wfine[P2dex]]+[well[k] for k in Jdex]\n",
    "                        else:\n",
    "                            weight = [well[k] for k in Idex+[P1dex]+[P2dex]+Jdex]\n",
    "                        w[i,p1,p2,j] = reduce(lambda x, y: x * y, weight)\n",
    "    znewshape = (torch.prod(torch.tensor(z.shape[0:-1])).item(), z.shape[-1])\n",
    "    \n",
    "    # Reshape the input z two 2D tensor, (batchsize, ndims), required by the flow.prob.\n",
    "    x, logJ = nfm.forward_and_log_det(z.view(znewshape))\n",
    "    result = torch.exp(nfm.p.log_prob(x) + logJ)\n",
    "    # Reshape back to the Matrix form for loss calculation\n",
    "    return w*result.view(z.shape[0:-1])\n",
    "\n",
    "\n",
    "def insample_error(T1,P,T2,Pi):\n",
    "    T2newshape =(T2.shape[0], torch.prod(torch.tensor(T2.shape[1:])).item()) \n",
    "    T1newshape =(torch.prod(torch.tensor(T1.shape[0:-1])).item(), T1.shape[-1]) \n",
    "    Pinewshape =(T1newshape[0], T2newshape[1]) \n",
    "    return Pi.view(Pinewshape) - T1.view(T1newshape) @ torch.linalg.solve(P, T2.view(T2newshape)), torch.sum(T1.view(T1newshape) @ torch.linalg.solve(P, T2.view(T2newshape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([1, 0], dtype=torch.uint8), tensor([0, 1], dtype=torch.uint8)]\n"
     ]
    }
   ],
   "source": [
    "# Set up flow model\n",
    "ndims = 2\n",
    "batchsize = 1000\n",
    "delta = 0.3\n",
    "\n",
    "sigma_x = 0.15\n",
    "sigma_y = 0.75\n",
    "\n",
    "# Create diagonal covariance matrix\n",
    "cov = torch.diag(torch.tensor([sigma_x**2, sigma_y**2]))\n",
    "theta = torch.tensor(np.pi / 4)\n",
    "#theta = torch.tensor(0)\n",
    "target = benchmark.Gauss(batchsize,ndims,cov, theta)\n",
    "# Define flows\n",
    "K = 4\n",
    "torch.manual_seed(0)\n",
    "\n",
    "latent_size = ndims\n",
    "hidden_units = 4\n",
    "num_blocks = 2\n",
    "\n",
    "flows = []\n",
    "# for i in range(K):\n",
    "#     flows += [nf.flows.CoupledRationalQuadraticSpline(latent_size, num_blocks, hidden_units)]\n",
    "#     flows += [nf.flows.LULinearPermute(latent_size)]\n",
    "# flows += [nf.flows.CoupledRationalQuadraticSpline(latent_size, num_blocks, hidden_units)]\n",
    "# flows += [nf.flows.CoupledRationalQuadraticSpline(latent_size, num_blocks, hidden_units, reverse_mask=True)]\n",
    "\n",
    "masks = nf.utils.iflow_binary_masks(latent_size)  # mask0\n",
    "# masks = [torch.ones(num_input_channels)]\n",
    "print(masks)\n",
    "for mask in masks[::-1]:\n",
    "    flows += [nf.flows.CoupledRationalQuadraticSpline(latent_size, num_blocks, hidden_units, mask=mask)]\n",
    "# Set base distribuiton\n",
    "q0 = nf.distributions.base.Uniform(2, 0.0, 1.0)\n",
    "    \n",
    "# Construct flow model\n",
    "nfm = nf.NormalizingFlow(q0, flows, target)\n",
    "\n",
    "# Move model on GPU if available\n",
    "enable_cuda = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() and enable_cuda else 'cpu')\n",
    "nfm = nfm.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total model params 476\n"
     ]
    }
   ],
   "source": [
    "print(\"total model params\",sum(p.numel() for p in nfm.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quadrature grid number 15\n",
      "Integration value 0.45322325581371137\n",
      "In sample error 0.9958070055600824\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n"
     ]
    }
   ],
   "source": [
    "def target_prob(x):\n",
    "    x_tensor = torch.tensor(x)\n",
    "    return torch.exp(target.log_prob(x_tensor.view(1,x_tensor.shape[0])))\n",
    "xell, well = xfacpy.GK15(0, 1)\n",
    "\n",
    "# n=20\n",
    "# points, weights = np.polynomial.legendre.leggauss(n)\n",
    "# xell = 0.5 * (points + 1)\n",
    "# # Adjust the weights accordingly (scale by 0.5 due to the transformation)\n",
    "# well = 0.5 * weights\n",
    "\n",
    "print(\"Quadrature grid number\",len(xell))\n",
    "par = xfacpy.TensorCI2Param()\n",
    "par.weight = [well] * ndims\n",
    "par.bondDim = 2\n",
    "#xell = np.linspace(0.0, 1.0, 1000)\n",
    "#well = xell*0.0 + (xell[1]-xell[0])\n",
    "tci = xfacpy.CTensorCI2(target_prob, [xell] * ndims, par)\n",
    "#tci = xfacpy.CTensorCI1(gaussian, [xell] * ndims)\n",
    "# Estimate integral and error\n",
    "itci = []\n",
    "x = [0.78, 0.34]\n",
    "#print(target_prob(x))#, gaussian(x))\n",
    "hsweeps = range(1)\n",
    "#for hsweep in hsweeps:\n",
    "tci.iterate()\n",
    "tci.iterate()\n",
    "#itci.append(tci.get_TensorTrain().sum([well] * ndims))\n",
    "itci.append(tci.tt.sum([well] * ndims))\n",
    "print(\"Integration value\",itci[-1])\n",
    "print(\"In sample error\",tci.pivotError[-1])\n",
    "print(\"MPS rank\", [M.shape for M in tci.tt.core])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test sum Pi tensor(0.5633, grad_fn=<SumBackward0>)\n",
      "torch.Size([1, 15, 15]) torch.Size([15, 15]) torch.Size([15, 15, 1])\n"
     ]
    }
   ],
   "source": [
    "Iset = tci.getIset()\n",
    "Jset = tci.getJset()\n",
    "o = list(range(len(xell)))\n",
    "loss = torch.zeros(1)\n",
    "F = Ttensor(Iset[0], o, Jset[0], xell, ndims, nfm, well)\n",
    "for l in range(len(Jset)-1):\n",
    "    Pi = Pitensor(Iset[l], o, o, Jset[l+1], xell, ndims, nfm, well)\n",
    "    T1 = Ttensor(Iset[l], o, Jset[l], xell, ndims, nfm, well)\n",
    "    P = Ptensor(Iset[l+1], Jset[l],xell, ndims, nfm, well)\n",
    "    print(\"test sum Pi\",torch.sum(Pi))\n",
    "    T2 = Ttensor(Iset[l+1], o, Jset[l+1],xell, ndims, nfm, well)\n",
    "    T2newshape =(T2.shape[0], torch.prod(torch.tensor(T2.shape[1:])).item()) \n",
    "    Fnewshape =(torch.prod(torch.tensor(F.shape[0:-1])).item(), F.shape[-1]) \n",
    "    print(F.shape, P.shape, T2.shape)\n",
    "    F = F.view(Fnewshape) @ torch.linalg.solve(P, T2.view(T2newshape))\n",
    "    err = insample_error(T1, P, T2, Pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangtao/miniconda3/lib/python3.9/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "# Plot target distribution\n",
    "# x_np, _ = make_moons(2 ** 20, noise=0.1)\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.hist2d(x_np[:, 0], x_np[:, 1], bins=200)\n",
    "# plt.show()\n",
    "\n",
    "# Plot initial flow distribution\n",
    "grid_size = 100\n",
    "xx, yy = torch.meshgrid(torch.linspace(0.0, 1.0, grid_size), torch.linspace(0.0, 1.0, grid_size))\n",
    "zz = torch.cat([xx.unsqueeze(2), yy.unsqueeze(2)], 2).view(-1, 2)\n",
    "zz = zz.to(device)\n",
    "\n",
    "nfm.eval()\n",
    "log_prob = nfm.p.log_prob(zz).to('cpu').view(*xx.shape)\n",
    "prob = nfm.p.prob(zz).to('cpu').view(*xx.shape)\n",
    "nfm.train()\n",
    "prob = torch.exp(log_prob)\n",
    "prob[torch.isnan(prob)] = 0\n",
    "\n",
    "plt.figure(figsize=(13.5, 13.5))\n",
    "plt.pcolormesh(xx, yy, prob.data.numpy())\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig(\"target.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A wrapper \n",
    "def prob_model(z_list):\n",
    "    z =torch.tensor(z_list)\n",
    "    #print(xsize, x_input)\n",
    "    #z = torch.reshape(z, (1, len(z_list)))\n",
    "    x, logJ = nfm.forward_and_log_det(z.view((1, len(z_list))))\n",
    "#     print(target.prob(z.view((1, len(z_list)))))\n",
    "#     print(z, x, logJ, nfm.p.log_prob(x))\n",
    "    return torch.exp(nfm.p.log_prob(x) + logJ)\n",
    "# z = np.array([xell[0], xell[1]])\n",
    "# prob_model(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def integrate(num_samples, nfm):\n",
    "    \"\"\"Importance sampling integration with flow-based approximate distribution\n",
    "\n",
    "    Args:\n",
    "      num_samples: Number of samples to draw\n",
    "\n",
    "    Returns:\n",
    "      mean, variance\n",
    "    \"\"\"\n",
    "#     z, log_q = nfm.sample(num_samples)\n",
    "#     q = torch.exp(log_q)\n",
    "#     func = nfm.p.prob(z)\n",
    "#     return torch.mean(func / q, dim=0) , torch.mean(q, dim=0)\n",
    "    z, log_q_ = nfm.q0(num_samples)\n",
    "    x, logJ = nfm.forward_and_log_det(z)\n",
    "    logJ -= log_q_\n",
    "    #print(log_q_)\n",
    "    func = torch.exp(nfm.p.log_prob(x) + logJ)\n",
    "    func2 = nfm.p.prob(z)\n",
    "    return torch.mean(func, dim=0), torch.mean(torch.exp(-logJ), dim=0)#, torch.mean(func2, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @torch.no_grad()\n",
    "# def integrate(num_samples, nfm):\n",
    "#     \"\"\"Importance sampling integration with flow-based approximate distribution\n",
    "\n",
    "#     Args:\n",
    "#       num_samples: Number of samples to draw\n",
    "\n",
    "#     Returns:\n",
    "#       mean, variance\n",
    "#     \"\"\"\n",
    "#     z, log_q = nfm.q0(num_samples)\n",
    "#     for flow in nfm.flows:\n",
    "#         z, log_det = flow(z)\n",
    "#         log_q -= log_det\n",
    "#     q = torch.exp(log_q)\n",
    "#     func = nfm.p.prob(z)\n",
    "#     return torch.mean(func / q, dim=0) , torch.mean(q, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nn = 10\n",
    "# result = 0\n",
    "# for _ in range(nn):\n",
    "#     r = integrate(1000000, nfm)\n",
    "#     print(r)\n",
    "#     #result += r#*r[1]\n",
    "#     print(r[0], r[1]) #, r[2])\n",
    "#     result += r[0]#*r[1]\n",
    "# print(result/nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "xell, well = xfacpy.GK15(0, 1)\n",
    "# print(xell)\n",
    "# n = 50\n",
    "# points, weights = np.polynomial.legendre.leggauss(n)\n",
    "# xell = 0.5 * (points + 1)\n",
    "# Adjust the weights accordingly (scale by 0.5 due to the transformation)\n",
    "# well = 0.5 * weights\n",
    "\n",
    "#xell = np.linspace(0.0, 1.0, 20)\n",
    "#well = xell*0.0 + (xell[1]-xell[0])\n",
    "# Add weight to parameter envokes environment error mode\n",
    "par = xfacpy.TensorCI2Param()\n",
    "par.weight = [well] * ndims\n",
    "par.pivot1 = [1]*ndims\n",
    "par.bondDim = 2 #max bond dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial integral error 0.56327004465845 -0.1131297508877217\n"
     ]
    }
   ],
   "source": [
    "tci = xfacpy.CTensorCI2(prob_model, [xell] * ndims, par)\n",
    "tci.iterate()\n",
    "tci.iterate()\n",
    "tci.iterate()\n",
    "tci.iterate()\n",
    "print(\"Initial integral error\", itci[-1], tci.tt.sum([well]*ndims) - itci[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▋                                        | 18/1000 [00:00<00:47, 20.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 0.756589812131395\n",
      "loss tensor([0.0476], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.24477348771031898\n",
      "integral error tensor(-0.2157, grad_fn=<SubBackward0>)\n",
      "current loss 0.04755919799208641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                       | 39/1000 [00:02<00:52, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.140667234419877\n",
      "loss tensor([0.0015], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.039524066196221286\n",
      "integral error tensor(-0.0340, grad_fn=<SubBackward0>)\n",
      "current loss 0.001451453659683466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██▍                                      | 59/1000 [00:04<00:52, 18.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.2211555325266001\n",
      "loss tensor([0.0310], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.20114435878519848\n",
      "integral error tensor(-0.1811, grad_fn=<SubBackward0>)\n",
      "current loss 0.031000211834907532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|███▏                                     | 79/1000 [00:05<00:53, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.708171586783747\n",
      "loss tensor([0.0167], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.17969573958116764\n",
      "integral error tensor(-0.1188, grad_fn=<SubBackward0>)\n",
      "current loss 0.01665375381708145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|████                                     | 99/1000 [00:07<00:49, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.1727013871020593\n",
      "loss tensor([0.0148], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.1591085789515253\n",
      "integral error tensor(-0.1084, grad_fn=<SubBackward0>)\n",
      "current loss 0.01478580106049776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████▋                                   | 117/1000 [00:08<00:50, 17.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 3.005945179911179\n",
      "loss tensor([0.0086], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.1686789027199524\n",
      "integral error tensor(-0.1376, grad_fn=<SubBackward0>)\n",
      "current loss 0.008556713350117207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▌                                  | 138/1000 [00:10<00:46, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.2627014518842614\n",
      "loss tensor([0.0202], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.2672509660990901\n",
      "integral error tensor(-0.2789, grad_fn=<SubBackward0>)\n",
      "current loss 0.02018253318965435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|██████▎                                 | 159/1000 [00:11<00:46, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.7790104891426184\n",
      "loss tensor([0.0049], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.2911052303628417\n",
      "integral error tensor(-0.2479, grad_fn=<SubBackward0>)\n",
      "current loss 0.004941368941217661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████                                 | 177/1000 [00:13<00:48, 16.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.6028306476059822\n",
      "loss tensor([0.0132], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.3590811640716911\n",
      "integral error tensor(-0.2924, grad_fn=<SubBackward0>)\n",
      "current loss 0.013211044482886791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████▉                                | 198/1000 [00:14<00:43, 18.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9132811657679323\n",
      "loss tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.253215178076983\n",
      "integral error tensor(-0.1491, grad_fn=<SubBackward0>)\n",
      "current loss 0.0003020540752913803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|████████▊                               | 219/1000 [00:16<00:42, 18.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.2922514498578486\n",
      "loss tensor([0.0019], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.2510714388857604\n",
      "integral error tensor(-0.1639, grad_fn=<SubBackward0>)\n",
      "current loss 0.0018570476677268744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|█████████▍                              | 237/1000 [00:17<00:44, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.683890260269327\n",
      "loss tensor([3.0226e-05], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.127218000965937\n",
      "integral error tensor(-0.1355, grad_fn=<SubBackward0>)\n",
      "current loss 3.0226094168028794e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██████████▎                             | 258/1000 [00:19<00:40, 18.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.2823133314228263\n",
      "loss tensor([0.0003], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.1978469705638991\n",
      "integral error tensor(-0.0471, grad_fn=<SubBackward0>)\n",
      "current loss 0.00033243338111788034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|███████████▏                            | 279/1000 [00:20<00:39, 18.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 4.6606873803777304\n",
      "loss tensor([0.0002], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.16432061369583367\n",
      "integral error tensor(-0.0747, grad_fn=<SubBackward0>)\n",
      "current loss 0.00017680485325399786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███████████▉                            | 297/1000 [00:22<00:40, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 3.449782193030796\n",
      "loss tensor([3.4931e-05], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0729311647367632\n",
      "integral error tensor(-0.0647, grad_fn=<SubBackward0>)\n",
      "current loss 3.493104668450542e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|████████████▋                           | 317/1000 [00:23<00:37, 18.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.8047780390063224\n",
      "loss tensor([3.7952e-07], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0655989153646242\n",
      "integral error tensor(-0.0677, grad_fn=<SubBackward0>)\n",
      "current loss 3.79523754645561e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|█████████████▌                          | 338/1000 [00:25<00:36, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.873620798447762\n",
      "loss tensor([7.2042e-07], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06771190397757193\n",
      "integral error tensor(-0.0675, grad_fn=<SubBackward0>)\n",
      "current loss 7.20417460797762e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|██████████████▎                         | 358/1000 [00:27<00:35, 18.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9361410950696705\n",
      "loss tensor([2.7018e-08], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06746702616334649\n",
      "integral error tensor(-0.0677, grad_fn=<SubBackward0>)\n",
      "current loss 2.7017513559712825e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███████████████▏                        | 379/1000 [00:28<00:33, 18.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.913410260386341\n",
      "loss tensor([1.6780e-09], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06766740238115371\n",
      "integral error tensor(-0.0677, grad_fn=<SubBackward0>)\n",
      "current loss 1.6779913014630665e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████▉                        | 399/1000 [00:30<00:33, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.914781110024006\n",
      "loss tensor([1.3597e-09], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0676578664239228\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.3596983539088114e-09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████████████████▋                       | 418/1000 [00:31<00:33, 17.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9173501122695615\n",
      "loss tensor([2.3807e-11], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06763963379511284\n",
      "integral error tensor(-0.0677, grad_fn=<SubBackward0>)\n",
      "current loss 2.380658170597627e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████▍                      | 437/1000 [00:33<00:31, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916311152573064\n",
      "loss tensor([5.1787e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764894230746993\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 5.178749790113457e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|██████████████████▎                     | 458/1000 [00:34<00:30, 17.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916332117557318\n",
      "loss tensor([2.6910e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764754566452869\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.690981118491642e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|███████████████████▏                    | 479/1000 [00:36<00:28, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9164013818127117\n",
      "loss tensor([1.2690e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764871379566056\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.2690044327856587e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████▉                    | 497/1000 [00:37<00:29, 17.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9163871535061396\n",
      "loss tensor([2.4595e-15], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764788048938647\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.4594584181747425e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|████████████████████▋                   | 518/1000 [00:39<00:26, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 0.8354942981249661\n",
      "loss tensor([1.9921e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764801832265988\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.9921046149479205e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████████████████████▌                  | 539/1000 [00:40<00:25, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9163847338964164\n",
      "loss tensor([1.3326e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764709290070153\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.3325800966162982e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|██████████████████████▎                 | 557/1000 [00:42<00:24, 17.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 0.9404881681523689\n",
      "loss tensor([3.1147e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764745876279299\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 3.114717685159807e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|███████████████████████                 | 578/1000 [00:43<00:23, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9164382980789285\n",
      "loss tensor([2.1962e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0676492281243542\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.196226273759594e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|███████████████████████▉                | 599/1000 [00:45<00:22, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916384996122808\n",
      "loss tensor([9.2555e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0676470710542057\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 9.255521696283076e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|████████████████████████▋               | 617/1000 [00:46<00:22, 17.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916382431858029\n",
      "loss tensor([1.5268e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764626201934504\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.5267869434010262e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|█████████████████████████▌              | 638/1000 [00:48<00:20, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916383978427312\n",
      "loss tensor([9.4401e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764686922530805\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 9.440109284553078e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████████████████████████▎             | 659/1000 [00:50<00:18, 18.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9163831807624194\n",
      "loss tensor([4.0699e-15], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764698723239837\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 4.0698781150760865e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|███████████████████████████             | 677/1000 [00:51<00:18, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 1.0875942468497688\n",
      "loss tensor([6.4113e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764736237469882\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 6.411278300789969e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████▉            | 698/1000 [00:53<00:16, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916397426634942\n",
      "loss tensor([1.6413e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764781525150648\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.6412652487085566e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|████████████████████████████▊           | 719/1000 [00:54<00:15, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916396916714432\n",
      "loss tensor([1.1601e-12], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764762962562382\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.1600896025060203e-12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|█████████████████████████████▍          | 737/1000 [00:56<00:15, 17.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916393108089694\n",
      "loss tensor([1.3843e-13], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0676476804119534\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.384311502233837e-13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|██████████████████████████████▎         | 757/1000 [00:57<00:13, 18.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.9164082456582934\n",
      "loss tensor([8.2031e-15], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764768691186179\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 8.203127847133951e-15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████████████████████████████         | 778/1000 [00:59<00:12, 18.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.91637993389921\n",
      "loss tensor([9.3030e-16], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764791814458193\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 9.30299674101187e-16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████████████████████████████▉        | 799/1000 [01:00<00:10, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 0.8354933213607089\n",
      "loss tensor([2.1516e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764828600258976\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.1515992112974835e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████▋       | 817/1000 [01:02<00:10, 17.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([2.1516e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.0676483011041088\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.1515992112974835e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|█████████████████████████████████▍      | 837/1000 [01:03<00:09, 18.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 0.8354933213607089\n",
      "loss tensor([1.2077e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.2077144839750531e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████▎     | 859/1000 [01:05<00:07, 19.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([1.2077e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.2077144839750531e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|███████████████████████████████████     | 877/1000 [01:06<00:07, 17.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([2.1516e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.1515992112974835e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████████▉    | 897/1000 [01:08<00:05, 18.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([2.1516e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.1515992112974835e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|████████████████████████████████████▋   | 918/1000 [01:10<00:04, 18.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([1.1772e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830033066216\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.177205034841311e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████████████████████████████████▌  | 939/1000 [01:11<00:03, 16.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([1.2077e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764829954850404\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.2077144839750531e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|██████████████████████████████████████▎ | 958/1000 [01:13<00:02, 17.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([2.0838e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 2.0838365755171395e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|███████████████████████████████████████ | 978/1000 [01:14<00:01, 17.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([1.2077e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830110068693\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.2077144839750531e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████▉| 999/1000 [01:16<00:00, 18.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in-sample tci error 2.916390994047912\n",
      "loss tensor([1.1772e-14], grad_fn=<DivBackward0>)\n",
      "[1, 2]\n",
      "[2, 1]\n",
      "MPS rank [(1, 15, 2), (2, 15, 1)]\n",
      "integral error -0.06764830032195068\n",
      "integral error tensor(-0.0676, grad_fn=<SubBackward0>)\n",
      "current loss 1.177205034841311e-14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1000/1000 [01:16<00:00, 13.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "max_iter = 1000\n",
    "num_samples = 1000\n",
    "show_iter = 20\n",
    "clip = 10.0\n",
    "\n",
    "loss_hist = np.array([])\n",
    "integral_error_hist = np.array([])\n",
    "in_sample_error_list = np.array([])\n",
    "int_error_hist = np.array([])\n",
    "optimizer = torch.optim.Adam(nfm.parameters(), lr=8e-4)#, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, max_iter)\n",
    "\n",
    "# n = 30\n",
    "# points, weights = np.polynomial.legendre.leggauss(n)\n",
    "# xfine = 0.5 * (points + 1)\n",
    "# # Adjust the weights accordingly (scale by 0.5 due to the transformation)\n",
    "# wfine = 0.5 * weights\n",
    "tci = xfacpy.CTensorCI2(prob_model, [xell] * ndims, par) \n",
    "tci.iterate()\n",
    "Iset = tci.getIset()\n",
    "Jset = tci.getJset()\n",
    "o = list(range(len(xell)))\n",
    "#integral_error_hist = np.append(integral_error_hist, np.fabs(tci.tt.sum([well]*ndims) - itci[-1]))\n",
    "for it in tqdm(range(max_iter)):\n",
    "    optimizer.zero_grad()\n",
    "    #tci.iterate()      \n",
    "    #hsweeps = range(1, 2)\n",
    "    #for hsweep in hsweeps:\n",
    "    loss = torch.zeros(1)\n",
    "    #F = Ttensor(Iset[0], o, Jset[0], xell, ndims, nfm, well)\n",
    "    for l in range(len(Jset)-1):\n",
    "        Pi = Pitensor(Iset[l], o, o, Jset[l+1], xell, ndims, nfm, well)#, xfine, wfine)\n",
    "        T1 = Ttensor(Iset[l], o, Jset[l], xell, ndims, nfm, well)#, xfine, wfine)\n",
    "        P = Ptensor(Iset[l+1], Jset[l],xell, ndims, nfm, well)\n",
    "        #print(\"test sum Pi\",torch.sum(Pi))\n",
    "        T2 = Ttensor(Iset[l+1], o, Jset[l+1],xell, ndims, nfm, well)#, xfine, wfine)\n",
    "        # err = torch.mean(torch.square(insample_error(T1, P, T2, Pi)))\n",
    "        err, int_value = insample_error(T1, P, T2, Pi)\n",
    "        #print(err,int_value)\n",
    "        #loss += torch.sum(torch.square(err))\n",
    "        loss += torch.square(torch.sum(err))\n",
    "    loss = loss/(len(Jset)-1)\n",
    "    #loss = nfm.reverse_kld(num_samples)\n",
    "    int_error_hist=np.append(int_error_hist, np.fabs(int_value.item()-itci[-1]))\n",
    "    integral_error_hist = np.append(integral_error_hist, np.fabs(tci.tt.sum([well]*ndims) - itci[-1]))\n",
    "    in_sample_error_list = np.append(in_sample_error_list, tci.pivotError[-1])\n",
    "    # Do backprop and optimizer step\n",
    "    if ~(torch.isnan(loss) | torch.isinf(loss)):\n",
    "        loss.backward()\n",
    "#         if (it+1)%show_iter == 0:\n",
    "#             #print(loss, loss2)\n",
    "#             # make_dot(z, params=dict(nfm.named_parameters()))\n",
    "#             for name, param in nfm.named_parameters():\n",
    "#                 print(f\"Gradient of {name} is \\n{param.grad}\")\n",
    "        torch.nn.utils.clip_grad_value_(nfm.parameters(), clip)\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Log loss\n",
    "    loss_hist = np.append(loss_hist, loss.to('cpu').data.numpy())\n",
    "    \n",
    "    # Plot learned distribution\n",
    "    if (it + 1) % show_iter == 0:\n",
    "        print(\"in-sample tci error\",tci.pivotError[-1])\n",
    "        print(\"loss\",loss)\n",
    "        print([len(I) for I in tci.getIset()])\n",
    "        print([len(J) for J in tci.getJset()])\n",
    "        #print(\"MPS rank\", [M.shape for M in tci.get_TensorTrain().core])\n",
    "        print(\"MPS rank\", [M.shape for M in tci.tt.core])\n",
    "        #print(\"integral error\", tci.get_TensorTrain().sum([well]*ndims) - itci[-1] )\n",
    "        print(\"integral error\", tci.tt.sum([well]*ndims) - itci[-1] )\n",
    "        print(\"integral error\", int_value - itci[-1] )\n",
    "        print(\"current loss\", loss_hist[-1])\n",
    "        tci = xfacpy.CTensorCI2(prob_model, [xell] * ndims, par) \n",
    "        for _ in range(5):\n",
    "            tci.iterate()\n",
    "        Iset = tci.getIset()\n",
    "        Jset = tci.getJset()\n",
    "        #print(\"integral error\", torch.sum(Pi) - itci[-1] )\n",
    "        nfm.eval()\n",
    "        log_prob = nfm.log_prob(zz)\n",
    "        nfm.train()\n",
    "        prob = torch.exp(log_prob.to('cpu').view(*xx.shape))\n",
    "        prob[torch.isnan(prob)] = 0\n",
    "\n",
    "\n",
    "    #scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.figure(figsize=(13.5, 10))\n",
    "plt.plot(loss_hist[0:500], linewidth = 2.0,label='loss')\n",
    "plt.xlabel(\"Iteration\")\n",
    "#print(in_sample_error_list)\n",
    "#plt.plot(in_sample_error_list, label='in_sample')\n",
    "plt.legend()\n",
    "plt.savefig(\"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.24477352 0.2435307  0.24225248 0.24093495 0.23957614 0.23817549\n",
      " 0.23673589 0.23526041 0.23375188 0.23221312 0.23064719 0.22905595\n",
      " 0.22744162 0.22580643 0.22415228 0.22248251 0.22079824 0.21910299\n",
      " 0.21739743 0.21568475 0.03952403 0.03901191 0.03853555 0.03813578\n",
      " 0.03783275 0.03741963 0.03709079 0.03681005 0.03655328 0.0363114\n",
      " 0.03605212 0.03582479 0.03560377 0.03538306 0.03516198 0.03494014\n",
      " 0.03471656 0.03449113 0.03426344 0.03403349 0.20114435 0.2005489\n",
      " 0.19978754 0.19889138 0.19788877 0.19680486 0.19566326 0.194486\n",
      " 0.19329433 0.19211097 0.19095306 0.18983943 0.18878783 0.18781383\n",
      " 0.18687992 0.18598298 0.18500934 0.18368087 0.1823736  0.18109761\n",
      " 0.17969574 0.17798398 0.17624055 0.174244   0.17207764 0.16968251\n",
      " 0.1663538  0.1639076  0.1615638  0.15848146 0.15504221 0.15140192\n",
      " 0.14768819 0.14385383 0.13991628 0.13587956 0.13174535 0.12751685\n",
      " 0.12319834 0.11879383 0.15910856 0.15528531 0.15137769 0.14741944\n",
      " 0.14345784 0.13951085 0.13561146 0.13193126 0.12904943 0.12632422\n",
      " 0.12378658 0.12140538 0.11918767 0.11713771 0.11526067 0.11356254\n",
      " 0.1120428  0.1106878  0.1094744  0.10843067 0.16867889 0.16664694\n",
      " 0.16382001 0.16265498 0.1603211  0.15825034 0.15683688 0.15677763\n",
      " 0.15738244 0.15758712 0.15730072 0.15596984 0.15399314 0.15095354\n",
      " 0.15171148 0.14912156 0.14605255 0.14248825 0.14004473 0.13760756\n",
      " 0.26725091 0.26091428 0.2549359  0.25334789 0.25153069 0.2512937\n",
      " 0.2526534  0.25550939 0.2596334  0.2645591  0.26983635 0.26853238\n",
      " 0.27164416 0.2752061  0.27588589 0.27642427 0.27707    0.27772422\n",
      " 0.27839799 0.278904   0.2911051  0.29147608 0.290426   0.28737132\n",
      " 0.28241093 0.28173132 0.2802131  0.27621878 0.27290667 0.27048506\n",
      " 0.26791776 0.26566668 0.26362513 0.26433919 0.26255829 0.25759251\n",
      " 0.2560683  0.25308142 0.24835629 0.24791713 0.35908113 0.35697886\n",
      " 0.35542087 0.34968868 0.33920766 0.32440318 0.32266998 0.31919861\n",
      " 0.31360894 0.30889077 0.30721543 0.30488012 0.30209048 0.29882939\n",
      " 0.29930357 0.2993897  0.29791559 0.29495914 0.29429255 0.292406\n",
      " 0.25321541 0.24515272 0.23026503 0.2083043  0.20840491 0.21468545\n",
      " 0.21956117 0.22256197 0.22359667 0.22074084 0.21525635 0.20801966\n",
      " 0.19818808 0.18675999 0.1751305  0.16416181 0.15538318 0.149855\n",
      " 0.14804615 0.14909591 0.25107173 0.25139217 0.2510034  0.24996988\n",
      " 0.24833889 0.24608989 0.24317585 0.23939953 0.23494269 0.22967575\n",
      " 0.22343977 0.21650366 0.20948346 0.2024558  0.1953     0.18804104\n",
      " 0.18117724 0.17479248 0.1690055  0.16385032 0.1272182  0.1279902\n",
      " 0.12821604 0.12784464 0.12686656 0.12531839 0.12493406 0.12512897\n",
      " 0.12461097 0.12375305 0.12290571 0.12060968 0.11953898 0.12049912\n",
      " 0.12322603 0.12691991 0.1306564  0.13312129 0.13462247 0.13547106\n",
      " 0.19784705 0.19399108 0.18578608 0.17236815 0.1527466  0.12554072\n",
      " 0.10192819 0.08637495 0.07267429 0.06111403 0.05152507 0.0428458\n",
      " 0.03709788 0.03389169 0.03280486 0.0334477  0.03547229 0.03859789\n",
      " 0.04256238 0.04712893 0.16432042 0.16436504 0.16376053 0.16220338\n",
      " 0.15829374 0.15177731 0.14098797 0.12328596 0.10859756 0.10216666\n",
      " 0.0946107  0.08378948 0.07832779 0.07725452 0.07873158 0.08125441\n",
      " 0.08029972 0.078452   0.07656224 0.0746976  0.07293172 0.07134004\n",
      " 0.06997256 0.06886036 0.06800975 0.06740705 0.06702764 0.06684245\n",
      " 0.06682355 0.06693391 0.0671461  0.06742282 0.06707616 0.06557063\n",
      " 0.06440152 0.06365265 0.0633568  0.06348891 0.06398059 0.06472106\n",
      " 0.06559898 0.06650339 0.06735264 0.0671087  0.06688507 0.06670345\n",
      " 0.06656714 0.06647967 0.06644352 0.06645025 0.06650068 0.0665846\n",
      " 0.06669582 0.0668325  0.0669821  0.06713767 0.06729315 0.06744469\n",
      " 0.06758423 0.06770746 0.06771172 0.06756131 0.06748695 0.06748987\n",
      " 0.06756596 0.06770627 0.0678976  0.06784002 0.06777851 0.06771587\n",
      " 0.067659   0.06760253 0.0675527  0.06751282 0.06748052 0.0674565\n",
      " 0.06744082 0.06743811 0.06744061 0.06745057 0.06746743 0.06748847\n",
      " 0.06751458 0.067544   0.06756957 0.06759838 0.06762774 0.06765063\n",
      " 0.06767232 0.06769232 0.06770567 0.06771667 0.06772221 0.06772487\n",
      " 0.06772168 0.06771685 0.06771244 0.06769944 0.06768997 0.06767677\n",
      " 0.06766672 0.06765558 0.06764294 0.06763001 0.06762416 0.06761734\n",
      " 0.06761391 0.06761096 0.06761051 0.06760867 0.06761171 0.06761481\n",
      " 0.0676188  0.06762431 0.06763081 0.06763442 0.06764076 0.0676458\n",
      " 0.06765152 0.06765593 0.06765736 0.0676618  0.06766258 0.06766332\n",
      " 0.06766192 0.06766398 0.06766195 0.06766022 0.06765677 0.06765546\n",
      " 0.06765271 0.06764985 0.06764678 0.06764538 0.06764163 0.06764219\n",
      " 0.06764008 0.06764035 0.06763918 0.06763972 0.06763942 0.06764222\n",
      " 0.06764273 0.06764267 0.06764523 0.06764595 0.06764765 0.0676481\n",
      " 0.06764717 0.06764777 0.06764884 0.06765215 0.06765173 0.06765018\n",
      " 0.06765188 0.06765069 0.06765087 0.06764932 0.06764833 0.06765003\n",
      " 0.06764893 0.06764681 0.06764619 0.06764792 0.06764842 0.06764666\n",
      " 0.06764726 0.06764646 0.0676458  0.06764652 0.06764604 0.06764589\n",
      " 0.06764589 0.06764616 0.06764529 0.06764741 0.06764723 0.0676481\n",
      " 0.06764628 0.06764732 0.06764795 0.06764735 0.06764735 0.06764723\n",
      " 0.06764768 0.06764678 0.06764553 0.06764821 0.06764818 0.06764663\n",
      " 0.06764905 0.06764976 0.06764798 0.06764759 0.06764759 0.06764935\n",
      " 0.06764869 0.06764991 0.06764604 0.06764854 0.06764875 0.06764792\n",
      " 0.06764726 0.06764792 0.06764783 0.06764786 0.06764777 0.06764672\n",
      " 0.06764815 0.06764771 0.06764813 0.06764818 0.06764666 0.06764991\n",
      " 0.06764964 0.06764896 0.06764979 0.06764789 0.06764854 0.06764762\n",
      " 0.06764813 0.06764813 0.06764807 0.06764845 0.0676481  0.06764801\n",
      " 0.06764801 0.06764795 0.06764824 0.06764854 0.06764839 0.06764807\n",
      " 0.06764795 0.06764804 0.06764804 0.06764759 0.06764702 0.06764878\n",
      " 0.06764795 0.06764795 0.06764807 0.06764807 0.06764723 0.06764726\n",
      " 0.06764705 0.06764666 0.0676492  0.06764932 0.06764634 0.06764625\n",
      " 0.06764625 0.06764625 0.06764929 0.06764973 0.06764643 0.06764729\n",
      " 0.06764619 0.06764619 0.06764735 0.06764628 0.06765027 0.06765027\n",
      " 0.06764649 0.06764732 0.06764726 0.06764726 0.06764726 0.06764732\n",
      " 0.06764693 0.06764658 0.06764896 0.06764896 0.06764699 0.06764678\n",
      " 0.06764699 0.06764738 0.0676486  0.06764866 0.06764699 0.06764663\n",
      " 0.06764663 0.06764669 0.06764705 0.06764881 0.06764881 0.06764687\n",
      " 0.06764693 0.06764696 0.06764696 0.06764699 0.06764711 0.06764893\n",
      " 0.06764899 0.06764699 0.06764702 0.06764649 0.06764646 0.06764705\n",
      " 0.0676472  0.06764881 0.06764881 0.06764732 0.06764666 0.06764666\n",
      " 0.06764735 0.06764872 0.06764872 0.06764705 0.0676472  0.0676472\n",
      " 0.0676472  0.06764705 0.0676486  0.0676486  0.06764705 0.06764675\n",
      " 0.06764708 0.06764938 0.06764935 0.06764601 0.06764619 0.06764619\n",
      " 0.06764592 0.06764964 0.06764964 0.06764646 0.06764649 0.06764646\n",
      " 0.0676464  0.06764884 0.06764932 0.06764881 0.06764669 0.0676464\n",
      " 0.0676464  0.06764666 0.06764869 0.06764866 0.06764678 0.06764681\n",
      " 0.06764717 0.06764622 0.0676495  0.0676495  0.06764628 0.06764669\n",
      " 0.06764669 0.06764705 0.06764616 0.06764795 0.06764708 0.06764866\n",
      " 0.06764866 0.06764866 0.06764717 0.06764944 0.06764711 0.06764661\n",
      " 0.06764646 0.06764646 0.06764672 0.0676486  0.0676486  0.06764717\n",
      " 0.06764717 0.06764717 0.0676472  0.06764675 0.06764884 0.06764884\n",
      " 0.06764675 0.0676472  0.0676472  0.0676472  0.0676472  0.06764604\n",
      " 0.0676489  0.0676489  0.06764878 0.06764684 0.06764693 0.06764729\n",
      " 0.06764729 0.06764732 0.06764663 0.06764678 0.06764598 0.06764663\n",
      " 0.06764944 0.06765027 0.0676495  0.06764818 0.06764687 0.06764762\n",
      " 0.06764836 0.06764711 0.06764729 0.06764729 0.06764711 0.06764848\n",
      " 0.06764783 0.06764768 0.06764699 0.06764717 0.06764923 0.06764923\n",
      " 0.06764723 0.06764732 0.06764735 0.06764735 0.06764732 0.06764726\n",
      " 0.06764947 0.06765006 0.0676475  0.06764708 0.06764693 0.06764693\n",
      " 0.06764711 0.06764738 0.06764747 0.06764848 0.06764938 0.06764944\n",
      " 0.06764872 0.06764753 0.06764804 0.06764798 0.06764777 0.06764836\n",
      " 0.06764833 0.06764789 0.06764789 0.06764833 0.06764836 0.06764777\n",
      " 0.06764735 0.06764818 0.06764747 0.06764747 0.06764881 0.0676506\n",
      " 0.06764774 0.0676475  0.06764753 0.06764756 0.06764756 0.06764753\n",
      " 0.06764753 0.06764741 0.06764902 0.06764902 0.06764771 0.06764771\n",
      " 0.06764771 0.06764771 0.06764771 0.06764777 0.06764896 0.06764896\n",
      " 0.06764744 0.06764735 0.06764735 0.06764735 0.06764744 0.06764777\n",
      " 0.0676509  0.06764765 0.06764708 0.06764735 0.06764726 0.06764735\n",
      " 0.06764708 0.06764753 0.06764786 0.06764765 0.06764747 0.06764783\n",
      " 0.06764783 0.06764747 0.0676475  0.06765072 0.06764771 0.06764729\n",
      " 0.06764786 0.06764771 0.06764771 0.06764777 0.06764899 0.06764899\n",
      " 0.06764863 0.06764863 0.06764902 0.06764869 0.06764863 0.0676486\n",
      " 0.06764839 0.06764896 0.06764881 0.06764842 0.06764795 0.06764795\n",
      " 0.06764795 0.06764795 0.06764842 0.0676486  0.0676486  0.0676486\n",
      " 0.06764848 0.06764866 0.06764872 0.06764872 0.06764872 0.06764872\n",
      " 0.06764872 0.06764872 0.06764866 0.06764872 0.06764836 0.06764854\n",
      " 0.06764854 0.06764854 0.06764854 0.06764854 0.06764854 0.06764854\n",
      " 0.06764854 0.06764854 0.06764854 0.06764854 0.06764854 0.06764836\n",
      " 0.06764866 0.06764866 0.06764866 0.06764866 0.06764866 0.06764866\n",
      " 0.06764866 0.06764836 0.06764836 0.06764836 0.06764872 0.06764869\n",
      " 0.06764869 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764872 0.06764836\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836 0.06764836\n",
      " 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872 0.06764836\n",
      " 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872 0.06764872\n",
      " 0.06764836 0.06764836 0.06764872 0.06764872 0.06764836 0.06764872\n",
      " 0.06764872 0.06764836 0.06764836 0.06764872]\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(13.5, 10))\n",
    "#plt.plot(integral_error_hist, label='Int Error')\n",
    "print(int_error_hist)\n",
    "plt.plot(int_error_hist[0:500], linewidth = 2.0, label='Integration Error')\n",
    "plt.xlabel(\"Iteration\")\n",
    "#print(in_sample_error_list)\n",
    "#plt.plot(in_sample_error_list, label='in_sample')\n",
    "plt.legend()\n",
    "plt.savefig(\"error.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfm.eval()\n",
    "log_prob = nfm.log_prob(zz)\n",
    "#x_new, logJ = nfm.forward_and_log_det(zz)\n",
    "#prob = torch.exp(nfm.p.log_prob(x_new) + logJ).view(*xx.shape)\n",
    "log_f = nfm.p.log_prob(zz)\n",
    "prob = torch.exp((log_f-log_prob).to('cpu').view(*xx.shape))\n",
    "\n",
    "prob[torch.isnan(prob)] = 0\n",
    "plt.figure(figsize=(13.5, 13.5))\n",
    "plt.pcolormesh(xx, yy, prob.data.numpy())\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.savefig(\"learned.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_q' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [11], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m log_prob \u001b[38;5;241m=\u001b[39m nfm\u001b[38;5;241m.\u001b[39mq0\u001b[38;5;241m.\u001b[39mlog_prob(zz)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mxx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#print(prob)\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#log_prob = log_prob - log_q\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(log_prob,\u001b[43mlog_q\u001b[49m)\n\u001b[1;32m     22\u001b[0m nfm\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     23\u001b[0m prob \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_prob)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'log_q' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot target distribution\n",
    "# x_np, _ = make_moons(2 ** 20, noise=0.1)\n",
    "# plt.figure(figsize=(15, 15))\n",
    "# plt.hist2d(x_np[:, 0], x_np[:, 1], bins=200)\n",
    "# plt.show()\n",
    "\n",
    "# Plot initial flow distribution\n",
    "grid_size = 100\n",
    "xx, yy = torch.meshgrid(torch.linspace(0.0, 1.0, grid_size), torch.linspace(0.0, 1.0, grid_size))\n",
    "zz = torch.cat([xx.unsqueeze(2), yy.unsqueeze(2)], 2).view(-1, 2)\n",
    "zz = zz.to(device)\n",
    "\n",
    "nfm.eval()\n",
    "#log_prob = nfm.p.log_prob(zz).to('cpu').view(*xx.shape)\n",
    "#prob = nfm.p.prob(zz).to('cpu').view(*xx.shape)\n",
    "#prob = nfm.p.prob(zz).to('cpu').view(*xx.shape)\n",
    "#print(prob, log_prob)\n",
    "log_prob = nfm.q0.log_prob(zz).to('cpu').view(*xx.shape)\n",
    "#print(prob)\n",
    "#log_prob = log_prob - log_q\n",
    "print(log_prob,log_q)\n",
    "nfm.train()\n",
    "prob = torch.exp(log_prob)\n",
    "prob[torch.isnan(prob)] = 0\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.pcolormesh(xx, yy, prob.data.numpy())\n",
    "plt.gca().set_aspect('equal', 'box')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
